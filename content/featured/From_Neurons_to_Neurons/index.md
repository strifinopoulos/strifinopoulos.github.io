---
title: 'From Neurons to Neutrons: A Case Study in Interpretability'
summary: Mechanistic Interpretability promises a path toward fully understanding how neural networks make their predictions. We argue that neural networks can learn low-dimensional representations of their training data that are surprisingly faithful to human-derived domain knowledge. As a case study, we extract nuclear physics concepts by studying models trained to reproduce nuclear data.

tags:
  - ML
date: '2024-03-29T00:00:00Z'

# Optional external URL for project (replaces project detail page).
external_link: 'https://arxiv.org/abs/2405.17425'

image:
  caption: Artistic interpretation of NuCLR
  focal_point: Smart

url_pdf: 'https://arxiv.org/pdf/2405.17425'
---
